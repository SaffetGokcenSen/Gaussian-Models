{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation For Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryGaussianData:\n",
    "    def __init__(self, dist_mean, nonsingular_matrix, dist_cov_eigvalues, num_of_samples):\n",
    "        # 1-d numpy array for the mean of the distribution\n",
    "        self.dist_mean = dist_mean\n",
    "        # a nonsingular matrix to create the eigenvector matrix of the covariance matrix for the distribution\n",
    "        self.nonsingular_matrix = nonsingular_matrix\n",
    "        # 1-d array with eigenvalues to be used for the generation of the covariance matrix for the distribution\n",
    "        self.dist_cov_eigvalues = dist_cov_eigvalues\n",
    "        # number of samples from the distribution\n",
    "        self.num_of_samples = num_of_samples\n",
    "        \n",
    "    def compute_cov_matrix(self):\n",
    "        nonsingular_matrix = self.nonsingular_matrix\n",
    "        q, r = np.linalg.qr(nonsingular_matrix)\n",
    "        # normalize the eigenvector matrix of the covariance matrix for the distribution\n",
    "        for i in range(0, q.ndim):\n",
    "            q[i, :] = q[i, :] / np.linalg.norm(q[i, :])\n",
    "        eigenvalue_matrix = np.diag(self.dist_cov_eigvalues)\n",
    "        dist_cov_matrix = np.matmul(np.matmul(q, eigenvalue_matrix), q.T)\n",
    "        \n",
    "        return dist_cov_matrix\n",
    "    \n",
    "    \n",
    "    def sample_data(self):\n",
    "        dist_cov_matrix = self.compute_cov_matrix() \n",
    "        \n",
    "        return np.random.default_rng().multivariate_normal(mean=self.dist_mean, cov=dist_cov_matrix, size=self.num_of_samples)\n",
    "\n",
    "\n",
    "class MLEComputation:\n",
    "    def __init__(self, train_input, pi_class_mle):\n",
    "        # input data for training\n",
    "        self.train_input = train_input\n",
    "        # mle for class density\n",
    "        self.pi_class_mle = pi_class_mle\n",
    "    \n",
    "    def gaussian_mle_estimates(self):\n",
    "        mean_mle = np.mean(self.train_input, axis=0)\n",
    "        num_of_samples = self.train_input.shape[0]\n",
    "        num_of_features = self.train_input.shape[1]\n",
    "        cov_mle = np.zeros((num_of_features, num_of_features))\n",
    "        for i in range(0, num_of_samples):\n",
    "            centered_sample = self.train_input[i, :]-mean_mle\n",
    "            cov_mle = cov_mle + np.outer(centered_sample, centered_sample)\n",
    "        cov_mle = cov_mle/num_of_samples\n",
    "        \n",
    "        return mean_mle, cov_mle\n",
    "    \n",
    "    def compute_class_density_measure(self, x):\n",
    "        mean_mle, cov_mle = self.gaussian_mle_estimates()\n",
    "        return (multivariate_normal.pdf(x, mean=mean_mle, cov=cov_mle))*self.pi_class_mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the mean of the category 0 is:\n[1 2 3 4]\nnonsingular matrix for generating the eigenvector matrix of the covariance of the category 0 is:\n[[ 1.   2.   0.   0. ]\n [ 2.  -1.   0.   0. ]\n [ 0.   4.   3.   0. ]\n [ 0.   0.   2.5  5. ]]\neigenvalues of the covariance matrix of the distribution for the category 0:\n[1.  2.4 3.  3.8]\ncovariance matrix of the category 0\n[[ 2.84883485 -0.92441743 -0.45552178  0.27234043]\n [-0.92441743  1.46220871  0.22776089 -0.13617021]\n [-0.45552178  0.22776089  2.68470111 -0.17021277]\n [ 0.27234043 -0.13617021 -0.17021277  3.20425532]]\nverification for the eigenvalues of the covariance matrix of the category 0\n[1.  2.4 3.  3.8]\n"
    }
   ],
   "source": [
    "mean_0 = np.array([1, 2, 3, 4])\n",
    "print('the mean of the category 0 is:')\n",
    "print(mean_0)\n",
    "non_singular_0 = np.array([[1, 2, 0, 0], [2, -1, 0, 0], [0, 4, 3, 0], [0, 0, 2.5, 5]])\n",
    "print('nonsingular matrix for generating the eigenvector matrix of the covariance of the category 0 is:')\n",
    "print(non_singular_0)\n",
    "Lambda_0 = np.array([1, 2.4, 3, 3.8])\n",
    "print('eigenvalues of the covariance matrix of the distribution for the category 0:')\n",
    "print(Lambda_0)\n",
    "num_of_samples_0 = 1000\n",
    "category_0 = CategoryGaussianData(mean_0, non_singular_0, Lambda_0, num_of_samples_0)\n",
    "cov_0 = category_0.compute_cov_matrix() \n",
    "print('covariance matrix of the category 0')\n",
    "print(cov_0)\n",
    "print('verification for the eigenvalues of the covariance matrix of the category 0')\n",
    "print(np.linalg.eigvalsh(cov_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the mean of the category 1 is:\n[5 6 7 8]\nnonsingular matrix for generating the eigenvector matrix of the covariance of the category 1 is:\n[[ 1.   2.   0.   0. ]\n [ 2.  -1.   0.   0. ]\n [ 0.   4.   3.   0. ]\n [ 0.   0.   2.5  5. ]]\neigenvalues of the covariance matrix of the distribution for the category 1:\n[1.5 2.8 3.3 4.6]\ncovariance matrix of the category 1:\n[[ 3.43483283 -0.96741641 -0.55927052  0.44255319]\n [-0.96741641  1.98370821  0.27963526 -0.2212766 ]\n [-0.55927052  0.27963526  3.14954407 -0.27659574]\n [ 0.44255319 -0.2212766  -0.27659574  3.63191489]]\nverification for the eigenvalues of the covariance matrix of the category 1:\n[1.5 2.8 3.3 4.6]\n"
    }
   ],
   "source": [
    "mean_1 = np.array([5, 6, 7, 8])\n",
    "print('the mean of the category 1 is:')\n",
    "print(mean_1)\n",
    "non_singular_1 = np.array([[1, 2, 0, 0], [2, -1, 0, 0], [0, 4, 3, 0], [0, 0, 2.5, 5]])\n",
    "print('nonsingular matrix for generating the eigenvector matrix of the covariance of the category 1 is:')\n",
    "print(non_singular_1)\n",
    "Lambda_1 = np.array([1.5, 2.8, 3.3, 4.6])\n",
    "print('eigenvalues of the covariance matrix of the distribution for the category 1:')\n",
    "print(Lambda_1)\n",
    "num_of_samples_1 = 1000\n",
    "category_1 = CategoryGaussianData(mean_1, non_singular_1, Lambda_1, num_of_samples_1)\n",
    "cov_1 = category_1.compute_cov_matrix() \n",
    "print('covariance matrix of the category 1:')\n",
    "print(cov_1)\n",
    "print('verification for the eigenvalues of the covariance matrix of the category 1:')\n",
    "print(np.linalg.eigvalsh(cov_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mle estimate of the mean for the distribution of category 0:\n[1.0157809  2.00003318 3.08615235 3.90864414]\nmle estimate of the covariance for the distribution of category 0:\n[[ 2.8827374  -0.952854   -0.58154729 -0.05271566]\n [-0.952854    1.45160837  0.25585757 -0.12022135]\n [-0.58154729  0.25585757  2.66179369 -0.13736024]\n [-0.05271566 -0.12022135 -0.13736024  3.21900198]]\neigenvalues of the mle of the covariance matrix for the distribution of category 0:\n[0.96692017 2.27368761 3.22920342 3.74533023]\n"
    }
   ],
   "source": [
    "train_data_0 = category_0.sample_data()\n",
    "pi_c_0 = 1000 / 2000\n",
    "mle_0 = MLEComputation(train_data_0, pi_c_0)\n",
    "mean_mle, cov_mle = mle_0.gaussian_mle_estimates()\n",
    "print('mle estimate of the mean for the distribution of category 0:')\n",
    "print(mean_mle)\n",
    "print('mle estimate of the covariance for the distribution of category 0:')\n",
    "print(cov_mle)\n",
    "print('eigenvalues of the mle of the covariance matrix for the distribution of category 0:')\n",
    "print(np.linalg.eigvalsh(cov_mle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mle estimate of the mean for the distribution of category 1:\n[4.99735815 6.00066101 6.99533254 8.05629727]\nmle estimate of the covariance for the distribution of category 1:\n[[ 3.37374534 -0.85557137 -0.62327291  0.4884745 ]\n [-0.85557137  1.87394408  0.31969323 -0.15766198]\n [-0.62327291  0.31969323  3.17713627 -0.20995268]\n [ 0.4884745  -0.15766198 -0.20995268  3.52845774]]\neigenvalues of the mle of the covariance matrix for the distribution of category 1:\n[1.48355044 2.69327018 3.25295197 4.52351083]\n"
    }
   ],
   "source": [
    "train_data_1 = category_1.sample_data()\n",
    "pi_c_1 = 1000 / 2000\n",
    "mle_1 = MLEComputation(train_data_1, pi_c_1)\n",
    "mean_mle, cov_mle = mle_1.gaussian_mle_estimates()\n",
    "print('mle estimate of the mean for the distribution of category 1:')\n",
    "print(mean_mle)\n",
    "print('mle estimate of the covariance for the distribution of category 1:')\n",
    "print(cov_mle)\n",
    "print('eigenvalues of the mle of the covariance matrix for the distribution of category 1:')\n",
    "print(np.linalg.eigvalsh(cov_mle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mle of the class density measure for the class 0: 7.884593330301856e-06\nmle of the class density measure for the class 1: 3.892380099604455e-05\n"
    }
   ],
   "source": [
    "test_input = np.array([3, 4, 5, 6])\n",
    "print('mle of the class density measure for the class 0:', mle_0.compute_class_density_measure(test_input))\n",
    "print('mle of the class density measure for the class 1:', mle_1.compute_class_density_measure(test_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two results, it is observed that the mle's for the probability density measures of the two classes are close to each other for the test input $\\left [3, 4, 5, 6 \\right ]$. This test input is the half-way between the means of the distributions for the two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mle of the class density measure for the class 0: 0.0024493901901416755\nmle of the class density measure for the class 1: 5.362065420025527e-10\n"
    }
   ],
   "source": [
    "mle_0 = MLEComputation(train_data_0, pi_c_0)\n",
    "mle_1 = MLEComputation(train_data_1, pi_c_1)\n",
    "test_input = np.array([1, 2, 3, 4])\n",
    "print('mle of the class density measure for the class 0:', mle_0.compute_class_density_measure(test_input))\n",
    "print('mle of the class density measure for the class 1:', mle_1.compute_class_density_measure(test_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test input being equal to the mean of the distribution for the class 0, the above results are in compliance with the expectation that category 0 should be chosen by the mle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mle of the class density measure for the class 0: 2.448460117226407e-13\nmle of the class density measure for the class 1: 0.0016509712539116957\n"
    }
   ],
   "source": [
    "mle_0 = MLEComputation(train_data_0, pi_c_0)\n",
    "mle_1 = MLEComputation(train_data_1, pi_c_1)\n",
    "test_input = np.array([5, 6, 7, 8])\n",
    "print('mle of the class density measure for the class 0:', mle_0.compute_class_density_measure(test_input))\n",
    "print('mle of the class density measure for the class 1:', mle_1.compute_class_density_measure(test_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test input being equal to the mean of the distribution for the class 1, the above results are in compliance with the expectation that category 1 should be chosen by the mle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "Machine Learning A Probabilistic Perspective, Kevin P. Murphy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit8310662a02b7438fbbed63987e973f89"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}